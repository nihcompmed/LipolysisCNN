{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from copy import copy\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "#from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "torch.set_float32_matmul_precision('high')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcsv = pd.read_csv('****PUT THE INPUT TRAJECTORY(GIF) DATASET OF YOUR TRAINED NETWORK HERE.csv****', header=None)\n",
    "Ou = torch.tensor(outcsv.values, dtype=torch.float32)\n",
    "\n",
    "inpcsv = pd.read_csv('****PUT THE OUTPUT PARAMETER DATASET OF YOUR TRAINED NETWORK HERE.csv****', header=None)\n",
    "inputs = torch.tensor(inpcsv.values, dtype=torch.float32)#[:, :npara ]\n",
    "\n",
    "# npara=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain =10000\n",
    "max_lr =1e-3\n",
    "C1steep=10\n",
    "bsize_myinput=500\n",
    "seed=241216\n",
    "max_epochs=2000\n",
    "ep_maxlr=1000\n",
    "\n",
    "outputstGIF = Ou.reshape(Ou.shape[0], 16, 4).transpose(1, 2) \n",
    "min_vals = torch.min(inputs[:ntrain], dim=0).values \n",
    "max_vals = torch.max(inputs[:ntrain], dim=0).values \n",
    "# min_vals = torch.min(inputs_original, dim=0).values \n",
    "# max_vals = torch.max(inputs_original, dim=0).values \n",
    "\n",
    "inputs_rescaled = (inputs - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "row_t = outputstGIF[:, 0, :]  # \n",
    "row_G = outputstGIF[:, 1, :]  # \n",
    "row_I = outputstGIF[:, 2, :]  # \n",
    "row_F = outputstGIF[:, 3, :]  # \n",
    "row_1onG= torch.reciprocal(row_G)\n",
    "row_1onI= torch.reciprocal(row_I)\n",
    "row_1onF= torch.reciprocal(row_F)\n",
    "\n",
    "n_conv1outchannels=512\n",
    "n_conv2outchannels=512\n",
    "n_conv3outchannels=1024\n",
    "n_dense1=1024\n",
    "n_dense2=1024\n",
    "\n",
    "outputs = torch.cat((row_t.unsqueeze(1),row_G.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_I.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_G.unsqueeze(1),row_I.unsqueeze(1),\n",
    "                     row_I.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_G.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onG.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onI.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onF.unsqueeze(1)),dim=1)\n",
    "\n",
    "\n",
    "print(outputs.shape)\n",
    "print(min_vals.shape)\n",
    "print(max_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fee1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data_loaders(inputs_rescaled, npara, model_checkpoint, ntrain=ntrain, batch_size=bsize_myinput,  val_split=0.2, num_workers=8):\n",
    "    \n",
    "    \n",
    "    # Load the model from the checkpoint\n",
    "    if \"catonlytGIF\" in model_checkpoint or \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:\n",
    "        outputs = torch.cat((row_t.unsqueeze(1),row_G.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_I.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_G.unsqueeze(1),row_I.unsqueeze(1),\n",
    "                     row_I.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_G.unsqueeze(1),row_F.unsqueeze(1)),dim=1)\n",
    "    elif \"twithreciGIF\" in model_checkpoint:\n",
    "        outputs = torch.cat((row_t.unsqueeze(1),row_G.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_I.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_G.unsqueeze(1),row_I.unsqueeze(1),\n",
    "                     row_I.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_G.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onG.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onI.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onF.unsqueeze(1)),dim=1)\n",
    "        \n",
    "    elif \"fullreci\" in model_checkpoint:\n",
    "        outputs = torch.cat((row_t.unsqueeze(1),row_G.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_I.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_G.unsqueeze(1),row_I.unsqueeze(1),\n",
    "                     row_I.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_G.unsqueeze(1),row_F.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onG.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onI.unsqueeze(1),\n",
    "                     row_t.unsqueeze(1),row_1onF.unsqueeze(1),\n",
    "                     row_1onG.unsqueeze(1),row_1onI.unsqueeze(1),\n",
    "                     row_1onI.unsqueeze(1),row_1onF.unsqueeze(1),\n",
    "                     row_1onG.unsqueeze(1),row_1onF.unsqueeze(1)),dim=1)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unknown featureEngineering type in checkpoint filename.\")\n",
    "\n",
    "    X = outputs[:ntrain].unsqueeze(1)\n",
    "#     X_test = outputs[ntrain:].unsqueeze(1)\n",
    "    X_test = outputs[ntrain:ntrain+ntest].unsqueeze(1)\n",
    "    \n",
    "    \n",
    "    Y = inputs_rescaled[:ntrain, :npara]\n",
    "#     Y_test = inputs_rescaled[ntrain:, :npara]\n",
    "    Y_test = inputs_rescaled[ntrain:ntrain+ntest, :npara]\n",
    "    print(\"Xshape\",X.shape)\n",
    "    print(\"Yshape:\",Y.shape)\n",
    "    print(\"Xtestshape\",X_test.shape)\n",
    "    print(\"Ytestshape:\",Y_test.shape)\n",
    "    print(X_test[1234])\n",
    "    print(Y_test[1234])\n",
    "    \n",
    "    dataset = TensorDataset(X, Y)\n",
    "    testset = TensorDataset(X_test, Y_test)\n",
    "    val_size = int(len(dataset) * val_split)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, generator=torch.Generator().manual_seed(seed))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_post22_cat_tanh01(pl.LightningModule):\n",
    "    def __init__(self, batch_size,max_lr,conv3size1,npara):#learning_rate):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.max_lr=max_lr\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_conv1outchannels, kernel_size=(2,2),stride=(2,1))# \n",
    "        self.conv2 = nn.Conv2d(in_channels=n_conv1outchannels, out_channels=n_conv2outchannels, kernel_size=(3,2),stride=(3,1))#\n",
    "        self.replication_pad = nn.ReplicationPad2d((0, 1, 0, 0))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=n_conv2outchannels, out_channels=n_conv3outchannels, kernel_size=(conv3size1,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(3*n_conv3outchannels, n_dense1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(n_dense1,n_dense2)\n",
    "        self.dense3 = nn.Linear(n_dense2, npara)\n",
    "        \n",
    "    def forward(self, x):       \n",
    "        x_conv1 = self.conv1(x) \n",
    "        x_pad = self.replication_pad(x_conv1) \n",
    "        x_rep = x.repeat(1, n_conv2outchannels, 1, 1)\n",
    "        x_cat= torch.cat([x_rep[:, :, i:i+2, :] if i % 2 == 0 else x_pad[:, :, i//2:i//2+1, :]\n",
    "               for i in range(x_rep.size(2) + x_pad.size(2))], dim=2) #\n",
    "        x = self.conv2(x_cat) #12-27\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool1(x) \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense3(x)\n",
    "        x = (torch.tanh(x)+1)/2\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Model_post22_cat_relu(pl.LightningModule):\n",
    "    def __init__(self, batch_size,max_lr,conv3size1,npara):#learning_rate):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.max_lr=max_lr\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_conv1outchannels, kernel_size=(2,2),stride=(2,1))# \n",
    "        self.conv2 = nn.Conv2d(in_channels=n_conv1outchannels, out_channels=n_conv2outchannels, kernel_size=(3,2),stride=(3,1))#\n",
    "        self.replication_pad = nn.ReplicationPad2d((0, 1, 0, 0))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=n_conv2outchannels, out_channels=n_conv3outchannels, kernel_size=(conv3size1,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(3*n_conv3outchannels, n_dense1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(n_dense1,n_dense2)\n",
    "        self.dense3 = nn.Linear(n_dense2, npara)\n",
    "        \n",
    "    def forward(self, x):       \n",
    "        x_conv1 = self.conv1(x) \n",
    "        x_pad = self.replication_pad(x_conv1) \n",
    "        x_rep = x.repeat(1, n_conv2outchannels, 1, 1)\n",
    "        x_cat= torch.cat([x_rep[:, :, i:i+2, :] if i % 2 == 0 else x_pad[:, :, i//2:i//2+1, :]\n",
    "               for i in range(x_rep.size(2) + x_pad.size(2))], dim=2) #\n",
    "        x = self.conv2(x_cat) \n",
    "        x = self.pool1(x) \n",
    "        x = self.conv3(x) \n",
    "        x = self.pool1(x)     \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Model_post22_nocat_tanh01(pl.LightningModule):\n",
    "    def __init__(self, batch_size,max_lr,conv3size1,npara):#learning_rate):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.max_lr=max_lr\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_conv1outchannels, kernel_size=(2,2),stride=(2,1))# \n",
    "        self.conv2 = nn.Conv2d(in_channels=n_conv1outchannels, out_channels=n_conv2outchannels, kernel_size=(3,2),stride=(3,1))#\n",
    "        self.replication_pad = nn.ReplicationPad2d((0, 1, 0, 0))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=n_conv2outchannels, out_channels=n_conv3outchannels, kernel_size=(conv3size1,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(3*n_conv3outchannels, n_dense1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(n_dense1,n_dense2)\n",
    "        self.dense3 = nn.Linear(n_dense2, npara)\n",
    "        \n",
    "    def forward(self, x):       \n",
    "        x_conv1 = self.conv1(x) \n",
    "        x = self.pool1(x_conv1) \n",
    "        x = self.conv3(x) \n",
    "        x = self.pool1(x)   \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense3(x)\n",
    "        x = (torch.tanh(x)+1)/2\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Model_post22_nocat_relu(pl.LightningModule):\n",
    "    def __init__(self, batch_size,max_lr,conv3size1,npara):#learning_rate):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.max_lr=max_lr\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_conv1outchannels, kernel_size=(2,2),stride=(2,1))# \n",
    "        self.conv2 = nn.Conv2d(in_channels=n_conv1outchannels, out_channels=n_conv2outchannels, kernel_size=(3,2),stride=(3,1))#\n",
    "        self.replication_pad = nn.ReplicationPad2d((0, 1, 0, 0))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=n_conv2outchannels, out_channels=n_conv3outchannels, kernel_size=(conv3size1,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(3*n_conv3outchannels, n_dense1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(n_dense1,n_dense2)\n",
    "        self.dense3 = nn.Linear(n_dense2, npara)\n",
    "        \n",
    "    def forward(self, x):       \n",
    "        x_conv1 = self.conv1(x) \n",
    "        x = self.pool1(x_conv1) \n",
    "        x = self.conv3(x)\n",
    "        x = self.pool1(x)   \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE This block if you want to see the inference of trained network over training set\n",
    "\n",
    "def infertrain_and_plot(model_checkpoint, min_vals, \n",
    "                         max_vals, param_names, batch_size, max_lr):\n",
    "    \n",
    "    if \"catonlytGIF\" in model_checkpoint or \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:\n",
    "        conv3size1_real=6\n",
    "    elif \"twithreciGIF\" in model_checkpoint:\n",
    "        conv3size1_real=9\n",
    "    elif \"fullreci\" in model_checkpoint:\n",
    "        conv3size1_real=12\n",
    "    else:\n",
    "        raise ValueError(\"Unknown featureEngineering type in checkpoint filename.\")\n",
    "\n",
    "#     npara_real=npara\n",
    "    if \"noinferGIFb\" in model_checkpoint or \"npara6\" in model_checkpoint:\n",
    "        npara_real=6\n",
    "    elif \"inferGIFb\" in model_checkpoint or \"npara8\" in model_checkpoint:  \n",
    "        npara_real=8\n",
    "    elif \"inferGFbGF22\" in model_checkpoint or \"npara10\" in model_checkpoint:\n",
    "        npara_real=10\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Number of Parameters to be inferred in checkpoint filename.\")\n",
    "    \n",
    "    train_loader, val_loader, test_loader=prepare_data_loaders(inputs_rescaled=inputs_rescaled,npara=npara_real, model_checkpoint=model_checkpoint)\n",
    "                  \n",
    "    # Load the model from the checkpoint\n",
    "    if \"relu\" in model_checkpoint:\n",
    "        \n",
    "        if \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:\n",
    "            model_1 = Model_post22_nocat_relu.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )\n",
    "        else:\n",
    "            model_1 = Model_post22_cat_relu.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )    \n",
    "                \n",
    "    elif \"tanh01\" in model_checkpoint:\n",
    "        if \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:           \n",
    "            model_1 = Model_post22_nocat_tanh01.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )                  \n",
    "        else:\n",
    "            model_1 = Model_post22_cat_tanh01.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )\n",
    "                \n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type in checkpoint filename.\")\n",
    "\n",
    "    model_1.eval()\n",
    "    \n",
    "    # Prepare to store the model outputs and correct answers\n",
    "    all_outputs = []\n",
    "    all_correct_answers = []\n",
    "    num_samples = 0  # To keep track of the number of processed samples\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs, correct_answers = batch  # Assuming train_loader yields (input, target) pairs\n",
    "            print(inputs.shape)\n",
    "            print(correct_answers.shape)\n",
    "            outputs = model_1(inputs)\n",
    "            \n",
    "            all_outputs.append(outputs)\n",
    "            all_correct_answers.append(correct_answers)\n",
    "            num_samples += inputs.size(0)\n",
    "\n",
    "            if num_samples >= 10000:\n",
    "                break  # Stop once we've processed 10,00 samples\n",
    "\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)[:10000]\n",
    "    all_correct_answers = torch.cat(all_correct_answers, dim=0)[:10000]\n",
    "    op_rescaledback = all_outputs  * (max_vals[:npara_real] - min_vals[:npara_real]) + min_vals[:npara_real]\n",
    "    all_correct_answers = all_correct_answers * (max_vals[:npara_real] - min_vals[:npara_real]) + min_vals[:npara_real]\n",
    "    op_rescaledback_np = op_rescaledback.numpy()\n",
    "    correct_answers_np = all_correct_answers.numpy()\n",
    "\n",
    "    # Plot the results\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Set font size for titles, labels, and ticks\n",
    "    title_fontsize = 20\n",
    "    label_fontsize = 14\n",
    "    tick_fontsize = 12\n",
    "\n",
    "    for i in range(npara_real):\n",
    "        axes[i].scatter(correct_answers_np[:, i], op_rescaledback_np[:, i], alpha=0.5)\n",
    "        axes[i].set_xlabel(f\"True {param_names[i]}\", fontsize=label_fontsize)\n",
    "        axes[i].set_ylabel(f\"Inferred {param_names[i]}\", fontsize=label_fontsize)\n",
    "        axes[i].set_title(f\"{param_names[i]}\", fontsize=title_fontsize)\n",
    "        axes[i].plot([min(correct_answers_np[:, i]), max(correct_answers_np[:, i])], \n",
    "                     [min(correct_answers_np[:, i]), max(correct_answers_np[:, i])], \n",
    "                     'r--')  # Add a diagonal line for reference\n",
    "\n",
    "#         for j in range(correct_answers_np.shape[0]):\n",
    "#             axes[i].annotate(f'{j+1}', (correct_answers_np[j, i], op_rescaledback_np[j, i]),\n",
    "#                              textcoords=\"offset points\", xytext=(5,-5), ha='center', fontsize=8)\n",
    "            \n",
    "        # Adjust tick label font size\n",
    "        axes[i].tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "    plt.show()\n",
    "    return correct_answers_np,op_rescaledback_np\n",
    "\n",
    "param_names = ['$S_I$','$C_X$','$S_G$','$X_2$','$C_F$','$L_2$','$G_b$','$F_b$','G22','F22']\n",
    "\n",
    "### IMPORT your model_checkpoint here!\n",
    "### It is in the form of, for example:\n",
    "# model_checkpoint='model_GFX3DNN_catonlytGIF_mvlognmdirect_npara10_tanh01_241216_25020328_bestepoch=1213-val_loss=0.00003.ckpt'\n",
    "\n",
    "paratrain,parainfertrain=infertrain_and_plot(model_checkpoint, min_vals, \n",
    "                         max_vals, param_names, batch_size=bsize_myinput, max_lr=max_lr)\n",
    "\n",
    "### Example for saving:\n",
    "#np.savetxt(\"paratrain_Mvlognormaldirect_jobid.csv\", paratrain, delimiter=\",\") \n",
    "#np.savetxt(\"parainfertrain_Mvlognormaldirect_jobid.csv\", parainfertrain, delimiter=\",\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a235854",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE This block if you want to see the inference of trained network over the TESTING set\n",
    "\n",
    "def infertest_and_plot(model_checkpoint, min_vals, \n",
    "                         max_vals, param_names, batch_size, max_lr):\n",
    "    \n",
    "    if \"catonlytGIF\" in model_checkpoint or \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:\n",
    "        conv3size1_real=6\n",
    "    elif \"twithreciGIF\" in model_checkpoint:\n",
    "        conv3size1_real=9\n",
    "    elif \"fullreci\" in model_checkpoint:\n",
    "        conv3size1_real=12\n",
    "    else:\n",
    "        raise ValueError(\"Unknown featureEngineering type in checkpoint filename.\")\n",
    "\n",
    "#     npara_real=npara\n",
    "    if \"noinferGIFb\" in model_checkpoint or \"npara6\" in model_checkpoint:\n",
    "        npara_real=6\n",
    "    elif \"inferGIFb\" in model_checkpoint or \"npara8\" in model_checkpoint:  \n",
    "        npara_real=8\n",
    "    elif \"inferGFbGF22\" in model_checkpoint or \"npara10\" in model_checkpoint:\n",
    "        npara_real=10\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Number of Parameters to be inferred in checkpoint filename.\")\n",
    "    \n",
    "    train_loader, val_loader, test_loader=prepare_data_loaders(inputs_rescaled=inputs_rescaled,npara=npara_real, model_checkpoint=model_checkpoint)\n",
    "                  \n",
    "    # Load the model from the checkpoint\n",
    "    if \"relu\" in model_checkpoint:\n",
    "        \n",
    "        if \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:\n",
    "            model_1 = Model_post22_nocat_relu.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )\n",
    "        else:\n",
    "            model_1 = Model_post22_cat_relu.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )    \n",
    "                \n",
    "    elif \"tanh01\" in model_checkpoint:\n",
    "        if \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:           \n",
    "            model_1 = Model_post22_nocat_tanh01.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )                  \n",
    "        else:\n",
    "            model_1 = Model_post22_cat_tanh01.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )\n",
    "                \n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type in checkpoint filename.\")\n",
    "\n",
    "    model_1.eval()\n",
    "    \n",
    "    # Prepare to store the model outputs and correct answers\n",
    "    all_outputs = []\n",
    "    all_correct_answers = []\n",
    "    num_samples = 0  # To keep track of the number of processed samples\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, correct_answers = batch  # Assuming train_loader yields (input, target) pairs\n",
    "            print(inputs.shape)\n",
    "            print(correct_answers.shape)\n",
    "            outputs = model_1(inputs)\n",
    "            \n",
    "            all_outputs.append(outputs)\n",
    "            all_correct_answers.append(correct_answers)\n",
    "            num_samples += inputs.size(0)\n",
    "\n",
    "            if num_samples >= 10000:\n",
    "                break  # Stop once we've processed 10,00 samples\n",
    "\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)[:10000]\n",
    "    all_correct_answers = torch.cat(all_correct_answers, dim=0)[:10000]\n",
    "    op_rescaledback = all_outputs  * (max_vals[:npara_real] - min_vals[:npara_real]) + min_vals[:npara_real]\n",
    "    all_correct_answers = all_correct_answers * (max_vals[:npara_real] - min_vals[:npara_real]) + min_vals[:npara_real]\n",
    "    op_rescaledback_np = op_rescaledback.numpy()\n",
    "    correct_answers_np = all_correct_answers.numpy()\n",
    "\n",
    "    # Plot the results\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Set font size for titles, labels, and ticks\n",
    "    title_fontsize = 20\n",
    "    label_fontsize = 14\n",
    "    tick_fontsize = 12\n",
    "\n",
    "    for i in range(npara_real):\n",
    "        axes[i].scatter(correct_answers_np[:, i], op_rescaledback_np[:, i], alpha=0.5)\n",
    "        axes[i].set_xlabel(f\"True {param_names[i]}\", fontsize=label_fontsize)\n",
    "        axes[i].set_ylabel(f\"Inferred {param_names[i]}\", fontsize=label_fontsize)\n",
    "        axes[i].set_title(f\"{param_names[i]}\", fontsize=title_fontsize)\n",
    "        axes[i].plot([min(correct_answers_np[:, i]), max(correct_answers_np[:, i])], \n",
    "                     [min(correct_answers_np[:, i]), max(correct_answers_np[:, i])], \n",
    "                     'r--')  # Add a diagonal line for reference\n",
    "\n",
    "#         for j in range(correct_answers_np.shape[0]):\n",
    "#             axes[i].annotate(f'{j+1}', (correct_answers_np[j, i], op_rescaledback_np[j, i]),\n",
    "#                              textcoords=\"offset points\", xytext=(5,-5), ha='center', fontsize=8)\n",
    "            \n",
    "        # Adjust tick label font size\n",
    "        axes[i].tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "    plt.show()\n",
    "    return correct_answers_np,op_rescaledback_np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# param_names = ['$S_I$','$C_X$','$S_G$','$C_Y$','$X_2$','$C_F$','$L_2$','$yt_{22}$','$G_b$','$F_b$','Initial condition of $G$','Initial condition of $F$']\n",
    "param_names = ['$S_I$','$C_X$','$S_G$','$X_2$','$C_F$','$L_2$','$G_b$','$F_b$','G22','F22']\n",
    "\n",
    " \n",
    "### USE This block if you want to see the inference of trained network over the TESTING set\n",
    "\n",
    "def infertest_and_plot(model_checkpoint, ntrain, param_names, batch_size, max_lr):\n",
    "    # Determine feature engineering size\n",
    "    if \"catonlytGIF\" in model_checkpoint or \"noFE\" in model_checkpoint:\n",
    "        conv3size1_real = 6\n",
    "    elif \"twithreciGIF\" in model_checkpoint:\n",
    "        conv3size1_real = 9\n",
    "    elif \"fullreci\" in model_checkpoint:\n",
    "        conv3size1_real = 12\n",
    "    else:\n",
    "        raise ValueError(\"Unknown featureEngineering type in checkpoint filename.\")\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader, val_loader, test_loader = prepare_data_loaders(\n",
    "        npara=npara_real,\n",
    "        model_checkpoint=model_checkpoint,\n",
    "        ntrain=ntrain\n",
    "    )\n",
    "\n",
    "    # Load model\n",
    "    if \"relu\" in model_checkpoint:\n",
    "        ModelClass = Model2D_post22_nocat_relu if \"noFE\" in model_checkpoint else Model2D_post22_cat_relu\n",
    "    elif \"tanh01\" in model_checkpoint:\n",
    "        ModelClass = Model2D_post22_nocat_tanh01 if \"noFE\" in model_checkpoint else Model2D_post22_cat_tanh01\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type in checkpoint filename.\")\n",
    "\n",
    "    model_1 = ModelClass.load_from_checkpoint(\n",
    "        checkpoint_path=model_checkpoint,\n",
    "        batch_size=batch_size,\n",
    "        max_lr=max_lr,\n",
    "        conv3size1=conv3size1_real,\n",
    "        npara=npara_real,\n",
    "        map_location=torch.device('cpu')\n",
    "    )\n",
    "    model_1.eval()\n",
    "\n",
    "    # Compute min/max for rescaling\n",
    "    min_vals = torch.min(inputs[:ntrain], dim=0).values\n",
    "    max_vals = torch.max(inputs[:ntrain], dim=0).values\n",
    "\n",
    "    # Inference loop\n",
    "    all_outputs = []\n",
    "    all_correct = []\n",
    "    samples = 0\n",
    "    with torch.no_grad():\n",
    "        for ip, correct in test_loader:\n",
    "            out = model_1(ip)\n",
    "            all_outputs.append(out)\n",
    "            all_correct.append(correct)\n",
    "            samples += ip.size(0)\n",
    "            if samples >= 10000:\n",
    "                break\n",
    "\n",
    "    # Concatenate and trim\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)[:10000]\n",
    "    all_correct = torch.cat(all_correct, dim=0)[:10000]\n",
    "\n",
    "    # Rescale back to original\n",
    "    scale = max_vals[:npara_real] - min_vals[:npara_real]\n",
    "    op_rescaled = all_outputs * scale + min_vals[:npara_real]\n",
    "    correct_rescaled = all_correct * scale + min_vals[:npara_real]\n",
    "\n",
    "    return correct_rescaled.numpy(), op_rescaled.numpy()\n",
    "\n",
    "\n",
    "### IMPORT your model_checkpoint here!\n",
    "### It is in the form of, for example:\n",
    "# model_checkpoint='model_GFX3DNN_catonlytGIF_mvlognmdirect_npara10_tanh01_241216_25020328_bestepoch=1213-val_loss=0.00003.ckpt'\n",
    "\n",
    "paratest,parainfertest=infertest_and_plot(model_checkpoint, min_vals, \n",
    "                         max_vals, param_names, batch_size=bsize_myinput, max_lr=max_lr)\n",
    "\n",
    "### Example for saving:\n",
    "#np.savetxt(\"paratest_Mvlognormaldirect_jobid.csv\", paratest, delimiter=\",\") \n",
    "#np.savetxt(\"parainfertest_Mvlognormaldirect_jobid.csv\", parainfertest, delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_names = ['$S_I$','$C_X$','$S_G$','$X_2$','$C_F$','$L_2$','$G_b$','$F_b$','G22','F22']\n",
    "\n",
    "\n",
    "FFA = pd.read_csv('GFX3D25_optmF.csv', header=None).values\n",
    "Glu = pd.read_csv('GFX3D25_optmG.csv', header=None).values\n",
    "\n",
    "# denoiseFFA=pd.read_csv('FCdenoised_FFA_for250115_3930694data.csv', header=None).values\n",
    "Ins   = pd.read_csv('25FSIGT_Ins.csv', header=None).values\n",
    "\n",
    "correct_answers3Doptm = torch.tensor(pd.read_csv('GFX3Doptm_correctanswers.csv', header=None).values, dtype=torch.float32)\n",
    "\n",
    "tvec = [22,  24, 25, 27, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140,160, 180]\n",
    "optmdata25 = np.zeros((25, 4, 16))\n",
    "optmdata25[:, 0, :] = tvec\n",
    "optmdata25[:, 1, :] = Glu\n",
    "optmdata25[:, 2, :] = Ins\n",
    "optmdata25[:, 3, :] = FFA\n",
    "optmdata25_tensor = torch.tensor(optmdata25, dtype=torch.float32)\n",
    "\n",
    "row_t_optm = optmdata25_tensor[:, 0, :]\n",
    "row_G_optm = optmdata25_tensor[:, 1, :]\n",
    "row_I_optm = optmdata25_tensor[:, 2, :]\n",
    "row_F_optm = optmdata25_tensor[:, 3, :]\n",
    "row_1onG_optm = torch.reciprocal(row_G_optm)\n",
    "row_1onI_optm = torch.reciprocal(row_I_optm)\n",
    "row_1onF_optm = torch.reciprocal(row_F_optm)\n",
    "\n",
    "    \n",
    "def inferoptm_and_plot(correct_answers, model_checkpoint, min_vals,\n",
    "                         max_vals, param_names, batch_size=bsize_myinput, max_lr=max_lr):\n",
    "\n",
    "\n",
    "    if \"catonlytGIF\" in model_checkpoint or \"noFE\" in model_checkpoint or \"nocatnoFE\" in model_checkpoint:\n",
    "        optmdata25_FEinputs = torch.cat((row_t_optm.unsqueeze(1), row_G_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_I_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_F_optm.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "#                                      row_t.unsqueeze(1), row_1onG.unsqueeze(1),\n",
    "#                                      row_t.unsqueeze(1), row_1onI.unsqueeze(1),\n",
    "#                                      row_t.unsqueeze(1), row_1onF.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "\n",
    "\n",
    "        conv3size1_real=6\n",
    "    elif \"twithreciGIF\" in model_checkpoint:\n",
    "        conv3size1_real=9\n",
    "        optmdata25_FEinputs = torch.cat((row_t_optm.unsqueeze(1), row_G_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_I_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onG_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onI_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onF_optm.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "\n",
    "    elif \"fullreci\" in model_checkpoint:\n",
    "        conv3size1_real=12\n",
    "        optmdata25_FEinputs = torch.cat((row_t_optm.unsqueeze(1), row_G_optm.unsqueeze(1),\n",
    "                         row_t_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                         row_t_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                         row_G_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                         row_I_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                         row_G_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                         row_t_optm.unsqueeze(1), row_1onG_optm.unsqueeze(1),\n",
    "                         row_t_optm.unsqueeze(1), row_1onI_optm.unsqueeze(1),\n",
    "                         row_t_optm.unsqueeze(1), row_1onF_optm.unsqueeze(1),\n",
    "                         row_1onG_optm.unsqueeze(1), row_1onI_optm.unsqueeze(1),\n",
    "                         row_1onI_optm.unsqueeze(1), row_1onF_optm.unsqueeze(1),\n",
    "                         row_1onG_optm.unsqueeze(1), row_1onF_optm.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unknown featureEngineering type in checkpoint filename.\")\n",
    "\n",
    "        \n",
    "        \n",
    "    dataset_denoisedFFA = TensorDataset(optmdata25_FEinputs)\n",
    "    denoisedFFA_loader = DataLoader(dataset_denoisedFFA, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    if \"noinferGIFb\" in model_checkpoint or \"npara6\" in model_checkpoint:\n",
    "        npara_real=6\n",
    "    elif \"inferGIFb\" in model_checkpoint or \"npara8\" in model_checkpoint:  \n",
    "        npara_real=8\n",
    "    elif \"inferGFbGF22\" in model_checkpoint or \"npara10\" in model_checkpoint:\n",
    "        npara_real=10\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Number of Parameters to be inferred in checkpoint filename.\")\n",
    "    \n",
    "    train_loader, val_loader, test_loader=prepare_data_loaders(inputs_rescaled=inputs_rescaled,npara=npara_real, model_checkpoint=model_checkpoint)\n",
    "                  \n",
    "    # Load the model from the checkpoint\n",
    "    if \"relu\" in model_checkpoint:\n",
    "        \n",
    "        if \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:\n",
    "            model_1 = Model_post22_nocat_relu.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )\n",
    "        else:\n",
    "            model_1 = Model_post22_cat_relu.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )    \n",
    "                \n",
    "    elif \"tanh01\" in model_checkpoint:\n",
    "        if \"nocatnoFE\" in model_checkpoint or \"noFE\" in model_checkpoint:           \n",
    "            model_1 = Model_post22_nocat_tanh01.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )                  \n",
    "        else:\n",
    "            model_1 = Model_post22_cat_tanh01.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )\n",
    "                \n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type in checkpoint filename.\")\n",
    "\n",
    "\n",
    "    model_1.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in denoisedFFA_loader:\n",
    "            ip = batch[0]\n",
    "            op = model_1(ip)\n",
    "            break  # Only one batch is needed \n",
    "          \n",
    "    print(op.shape)\n",
    "    # Rescale the output back to the original scale\n",
    "    op_rescaledback = op * (max_vals[:npara_real] - min_vals[:npara_real]) + min_vals[:npara_real]\n",
    "    print(max_vals.shape)\n",
    "    # Convert to numpy for easier plotting\n",
    "    op_rescaledback_np = op_rescaledback.numpy()\n",
    "    correct_answers_np = correct_answers.numpy()\n",
    "    print(correct_answers_np.shape)\n",
    "\n",
    "    fig, axes = plt.subplots(3,4, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    title_fontsize = 20\n",
    "    label_fontsize = 14\n",
    "    tick_fontsize = 12\n",
    "    \n",
    "    # Indices of subjects to exclude\n",
    "#     exclude_indices = [2,10,17,24]  # Python uses zero-based indexing, so subjects 4 and 25 correspond to indices 3 and 24\n",
    "\n",
    "    # Filter out the excluded subjects\n",
    "    filtered_correct_answers =correct_answers_np# np.delete(correct_answers_np, exclude_indices, axis=0)#\n",
    "    filtered_op_rescaledback =op_rescaledback_np#np.delete(op_rescaledback_np, exclude_indices, axis=0)# \n",
    "    \n",
    "    \n",
    "    for i in range(npara_real):\n",
    "        axes[i].scatter(filtered_correct_answers[:, i], filtered_op_rescaledback[:, i], alpha=0.5)\n",
    "        axes[i].set_xlabel(f\"True {param_names[i]}\", fontsize=label_fontsize)\n",
    "        axes[i].set_ylabel(f\"Inferred {param_names[i]}\", fontsize=label_fontsize)\n",
    "        axes[i].set_title(f\"{param_names[i]}\", fontsize=title_fontsize)\n",
    "        axes[i].plot([min(filtered_correct_answers[:, i]), max(filtered_correct_answers[:, i])], \n",
    "                     [min(filtered_correct_answers[:, i]), max(filtered_correct_answers[:, i])], \n",
    "                     'r--')  # Add a diagonal line for reference\n",
    "        # Annotate remaining points\n",
    "        for j in range(filtered_correct_answers.shape[0]):\n",
    "            axes[i].annotate(f'{j+1}', (filtered_correct_answers[j, i], filtered_op_rescaledback[j, i]),\n",
    "                             textcoords=\"offset points\", xytext=(5, -5), ha='center', fontsize=8)\n",
    "\n",
    "        # Adjust tick label font size\n",
    "        axes[i].tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "    plt.show()\n",
    "    return filtered_op_rescaledback\n",
    "\n",
    "\n",
    "\n",
    "### USE This block if you want to see the inference of trained network from the MODEL-FITTING CURVE from optimization\n",
    "\n",
    "\n",
    "\n",
    "# correct_answers = torch.tensor(pd.read_csv('New75FSIGT_optmpara.csv', header=None).values, dtype=torch.float32)\n",
    "FFA = pd.read_csv('FX2D25_optmF.csv', header=None).values\n",
    "Glu = pd.read_csv('25FSIGT_glu_alltime.csv', header=None).values\n",
    "# denoiseFFA=pd.read_csv('FX2D25_FCdenoised_2877269datafirst500k_250203.csv', header=None).values\n",
    "Ins   = pd.read_csv('25FSIGT_ins_alltime.csv', header=None).values\n",
    "\n",
    "correct_answers2Doptm = torch.tensor(pd.read_csv('FX2D25_paraoptm.csv', header=None).values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "tvec =  [0,   2,   3,   4,   5,   6,   8,  10,  12,  14,  16,  19, 22,   24, 25, 27, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140,160, 180]\n",
    "# tvec = [22,  24, 25, 27, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140,160, 180]\n",
    "realdata25 = np.zeros((25, 4, 28))\n",
    "realdata25[:, 0, :] = tvec\n",
    "realdata25[:, 1, :] = Glu\n",
    "realdata25[:, 2, :] = Ins\n",
    "realdata25[:, 3, :] = FFA\n",
    "realdata25_tensor = torch.tensor(realdata25, dtype=torch.float32)\n",
    "\n",
    "row_t_optm = realdata25_tensor[:, 0, :]\n",
    "row_G_optm = realdata25_tensor[:, 1, :]\n",
    "row_I_optm = realdata25_tensor[:, 2, :]\n",
    "row_F_optm = realdata25_tensor[:, 3, :]\n",
    "row_1onG_optm = torch.reciprocal(row_G_optm)\n",
    "row_1onI_optm = torch.reciprocal(row_I_optm)\n",
    "row_1onF_optm = torch.reciprocal(row_F_optm)\n",
    "\n",
    "    \n",
    "def inferoptm_and_plot(correct_answers, model_checkpoint, ntrain, param_names, batch_size=bsize_myinput, max_lr=max_lr):\n",
    "\n",
    "\n",
    "    if \"catonlytGIF\" in model_checkpoint:\n",
    "        realdata25_FEinputs = torch.cat((row_t_optm.unsqueeze(1), row_G_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_I_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_F_optm.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "#                                      row_t.unsqueeze(1), row_1onG.unsqueeze(1),\n",
    "#                                      row_t.unsqueeze(1), row_1onI.unsqueeze(1),\n",
    "#                                      row_t.unsqueeze(1), row_1onF.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "        conv3size1_real=6\n",
    "    elif \"noFE\" in model_checkpoint:\n",
    "        realdata25_FEinputs = torch.cat((row_t_optm.unsqueeze(1), row_G_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_I_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_F_optm.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "\n",
    "\n",
    "        conv3size1_real=6\n",
    "    elif \"twithreciGIF\" in model_checkpoint:\n",
    "        conv3size1_real=9\n",
    "        realdata25_FEinputs = torch.cat((row_t_optm.unsqueeze(1), row_G_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_I_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onG_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onI_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onF_optm.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "        \n",
    "    elif \"fullreci\" in model_checkpoint:\n",
    "        conv3size1_real=12\n",
    "        realdata25_FEinputs = torch.cat((row_t_optm.unsqueeze(1), row_G_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_I_optm.unsqueeze(1),\n",
    "                                 row_I_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_G_optm.unsqueeze(1), row_F_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onG_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onI_optm.unsqueeze(1),\n",
    "                                 row_t_optm.unsqueeze(1), row_1onF_optm.unsqueeze(1),\n",
    "                                 row_1onG_optm.unsqueeze(1), row_1onI_optm.unsqueeze(1),\n",
    "                                 row_1onI_optm.unsqueeze(1), row_1onF_optm.unsqueeze(1),\n",
    "                                 row_1onG_optm.unsqueeze(1), row_1onF_optm.unsqueeze(1)), dim=1).unsqueeze(1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown featureEngineering type in checkpoint filename.\")\n",
    "\n",
    "    dataset_denoisedFFA = TensorDataset(realdata25_FEinputs)\n",
    "    denoisedFFA_loader = DataLoader(dataset_denoisedFFA, batch_size=batch_size, shuffle=False)\n",
    "    print(npara_real)\n",
    "\n",
    "    # Load the model from the checkpoint\n",
    "    if \"relu\" in model_checkpoint:\n",
    "        \n",
    "        if \"noFE\" in model_checkpoint or \"nocatnoFE\" in model_checkpoint:\n",
    "            model_1 = Model2D_post22_nocat_relu.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )\n",
    "        else:\n",
    "            model_1 = Model2D_post22_cat_relu.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )    \n",
    "                \n",
    "    elif \"tanh01\" in model_checkpoint:\n",
    "        if \"noFE\" in model_checkpoint or \"nocatnoFE\" in model_checkpoint:           \n",
    "            model_1 = Model2D_post22_nocat_tanh01.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )                  \n",
    "        else:\n",
    "            model_1 = Model2D_post22_cat_tanh01.load_from_checkpoint(\n",
    "                checkpoint_path=model_checkpoint,\n",
    "                batch_size=batch_size,max_lr=max_lr,conv3size1=conv3size1_real,npara=npara_real,\n",
    "                map_location=torch.device('cpu')\n",
    "            )\n",
    "                \n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type in checkpoint filename.\")\n",
    "\n",
    "\n",
    "    model_1.eval()\n",
    "    min_vals = torch.min(inputs[:ntrain], dim=0).values \n",
    "    max_vals = torch.max(inputs[:ntrain], dim=0).values \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in denoisedFFA_loader:\n",
    "            ip = batch[0]\n",
    "            op = model_1(ip)\n",
    "            break  # Only one batch is needed \n",
    "          \n",
    "    print(op.shape)\n",
    "    # Rescale the output back to the original scale\n",
    "    op_rescaledback = op * (max_vals[:npara_real] - min_vals[:npara_real]) + min_vals[:npara_real]\n",
    "    print(max_vals.shape)\n",
    "    # Convert to numpy for easier plotting\n",
    "    op_rescaledback_np = op_rescaledback.numpy()\n",
    "    correct_answers_np = correct_answers.numpy()\n",
    "    print(correct_answers_np.shape)\n",
    "\n",
    "    \n",
    "    # Indices of subjects to exclude\n",
    "#     exclude_indices = [2,10,17,24]  # Python uses zero-based indexing, so subjects 4 and 25 correspond to indices 3 and 24\n",
    "\n",
    "    # Filter out the excluded subjects\n",
    "    filtered_correct_answers =correct_answers_np# np.delete(correct_answers_np, exclude_indices, axis=0)#\n",
    "    filtered_op_rescaledback =op_rescaledback_np#np.delete(op_rescaledback_np, exclude_indices, axis=0)# \n",
    "    \n",
    "\n",
    "    return filtered_op_rescaledback\n",
    "\n",
    "### IMPORT your model_checkpoint here!\n",
    "### It is in the form of, for example:\n",
    "# model_checkpoint='model_GFX3DNN_catonlytGIF_mvlognmdirect_npara10_tanh01_241216_25020328_bestepoch=1213-val_loss=0.00003.ckpt'\n",
    "\n",
    "\n",
    "inferoptm = inferoptm_and_plot(correct_answers, model_checkpoint, min_vals, max_vals, param_names)\n",
    "### Example for saving:\n",
    "#np.savetxt(\"parainferfromoptm_Mvlognormaldirect_jobid.csv\", inferoptm, delimiter=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
