{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c63b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100/10000 - Loss: 1.200   lengthscale: 0.729   noise: 0.667  Max Loss Row: 14\n",
      "Iter 200/10000 - Loss: 1.441   lengthscale: 0.766   noise: 0.636  Max Loss Row: 19\n",
      "Iter 300/10000 - Loss: 1.517   lengthscale: 0.808   noise: 0.605  Max Loss Row: 1\n",
      "Iter 400/10000 - Loss: 1.269   lengthscale: 0.860   noise: 0.585  Max Loss Row: 10\n",
      "Iter 500/10000 - Loss: 1.957   lengthscale: 0.912   noise: 0.570  Max Loss Row: 8\n",
      "Iter 600/10000 - Loss: 1.331   lengthscale: 0.964   noise: 0.555  Max Loss Row: 16\n",
      "Iter 700/10000 - Loss: 1.291   lengthscale: 1.014   noise: 0.538  Max Loss Row: 3\n",
      "Iter 800/10000 - Loss: 1.249   lengthscale: 1.060   noise: 0.519  Max Loss Row: 13\n",
      "Iter 900/10000 - Loss: 1.171   lengthscale: 1.104   noise: 0.498  Max Loss Row: 7\n",
      "Iter 1000/10000 - Loss: 1.162   lengthscale: 1.154   noise: 0.478  Max Loss Row: 15\n",
      "Iter 1100/10000 - Loss: 1.150   lengthscale: 1.202   noise: 0.459  Max Loss Row: 15\n",
      "Iter 1200/10000 - Loss: 1.975   lengthscale: 1.245   noise: 0.438  Max Loss Row: 18\n",
      "Iter 1300/10000 - Loss: 1.328   lengthscale: 1.291   noise: 0.420  Max Loss Row: 6\n",
      "Iter 1400/10000 - Loss: 1.413   lengthscale: 1.339   noise: 0.401  Max Loss Row: 1\n",
      "Iter 1500/10000 - Loss: 1.177   lengthscale: 1.386   noise: 0.383  Max Loss Row: 10\n",
      "Iter 1600/10000 - Loss: 1.245   lengthscale: 1.432   noise: 0.365  Max Loss Row: 0\n",
      "Iter 1700/10000 - Loss: 1.943   lengthscale: 1.476   noise: 0.348  Max Loss Row: 8\n",
      "Iter 1800/10000 - Loss: 1.076   lengthscale: 1.531   noise: 0.334  Max Loss Row: 7\n",
      "Iter 1900/10000 - Loss: 0.951   lengthscale: 1.582   noise: 0.317  Max Loss Row: 5\n",
      "Iter 2000/10000 - Loss: 1.121   lengthscale: 1.616   noise: 0.299  Max Loss Row: 4\n",
      "Iter 2100/10000 - Loss: 1.011   lengthscale: 1.667   noise: 0.286  Max Loss Row: 21\n",
      "Iter 2200/10000 - Loss: 1.107   lengthscale: 1.711   noise: 0.272  Max Loss Row: 4\n",
      "Iter 2300/10000 - Loss: 1.305   lengthscale: 1.754   noise: 0.260  Max Loss Row: 11\n",
      "Iter 2400/10000 - Loss: 1.946   lengthscale: 1.805   noise: 0.251  Max Loss Row: 18\n",
      "Iter 2500/10000 - Loss: 1.017   lengthscale: 1.846   noise: 0.241  Max Loss Row: 7\n",
      "Iter 2600/10000 - Loss: 1.277   lengthscale: 1.887   noise: 0.229  Max Loss Row: 11\n",
      "Iter 2700/10000 - Loss: 1.960   lengthscale: 1.927   noise: 0.217  Max Loss Row: 18\n",
      "Iter 2800/10000 - Loss: 0.887   lengthscale: 1.965   noise: 0.208  Max Loss Row: 9\n",
      "Iter 2900/10000 - Loss: 1.072   lengthscale: 2.000   noise: 0.199  Max Loss Row: 20\n",
      "Iter 3000/10000 - Loss: 1.394   lengthscale: 2.043   noise: 0.191  Max Loss Row: 19\n",
      "Iter 3100/10000 - Loss: 1.091   lengthscale: 2.083   noise: 0.185  Max Loss Row: 10\n",
      "Iter 3200/10000 - Loss: 0.821   lengthscale: 2.121   noise: 0.181  Max Loss Row: 14\n",
      "Iter 3300/10000 - Loss: 1.339   lengthscale: 2.157   noise: 0.174  Max Loss Row: 1\n",
      "Iter 3400/10000 - Loss: 1.065   lengthscale: 2.192   noise: 0.169  Max Loss Row: 4\n",
      "Iter 3500/10000 - Loss: 1.092   lengthscale: 2.225   noise: 0.165  Max Loss Row: 10\n",
      "Iter 3600/10000 - Loss: 0.884   lengthscale: 2.267   noise: 0.159  Max Loss Row: 15\n",
      "Iter 3700/10000 - Loss: 0.911   lengthscale: 2.295   noise: 0.155  Max Loss Row: 16\n",
      "Iter 3800/10000 - Loss: 0.784   lengthscale: 2.324   noise: 0.151  Max Loss Row: 2\n",
      "Iter 3900/10000 - Loss: 0.961   lengthscale: 2.343   noise: 0.148  Max Loss Row: 7\n",
      "Iter 4000/10000 - Loss: 2.093   lengthscale: 2.369   noise: 0.146  Max Loss Row: 8\n",
      "Iter 4100/10000 - Loss: 1.032   lengthscale: 2.395   noise: 0.142  Max Loss Row: 20\n",
      "Iter 4200/10000 - Loss: 0.901   lengthscale: 2.421   noise: 0.141  Max Loss Row: 21\n",
      "Iter 4300/10000 - Loss: 1.337   lengthscale: 2.438   noise: 0.139  Max Loss Row: 1\n",
      "Iter 4400/10000 - Loss: 0.928   lengthscale: 2.464   noise: 0.136  Max Loss Row: 13\n",
      "Iter 4500/10000 - Loss: 1.247   lengthscale: 2.495   noise: 0.134  Max Loss Row: 11\n",
      "Iter 4600/10000 - Loss: 1.246   lengthscale: 2.517   noise: 0.133  Max Loss Row: 11\n",
      "Iter 4700/10000 - Loss: 1.463   lengthscale: 2.539   noise: 0.131  Max Loss Row: 19\n",
      "Iter 4800/10000 - Loss: 1.255   lengthscale: 2.562   noise: 0.131  Max Loss Row: 17\n",
      "Iter 4900/10000 - Loss: 1.334   lengthscale: 2.582   noise: 0.130  Max Loss Row: 1\n",
      "Iter 5000/10000 - Loss: 0.765   lengthscale: 2.598   noise: 0.130  Max Loss Row: 2\n",
      "Iter 5100/10000 - Loss: 0.756   lengthscale: 2.622   noise: 0.127  Max Loss Row: 14\n",
      "Loss is below the threshold. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "subjins25_csv = pd.read_csv('SubjIns25.csv', header=None)\n",
    "subjins25_data = subjins25_csv.values\n",
    "subjins25_data = np.delete(subjins25_data, [0, 5, 10], axis=0)\n",
    "\n",
    "torch.manual_seed(231127)\n",
    "train_x = torch.tensor([22., 24., 25., 27., 30., 40., 50., 60., 70., 80., 90., 100.,\n",
    "                        120., 140., 160., 180.], dtype=torch.float32)\n",
    "subjins25 = torch.tensor(subjins25_data, dtype=torch.float32)\n",
    "train_mean = torch.mean(torch.log(subjins25), dim=0)\n",
    "train_std = torch.std(torch.log(subjins25), dim=0)\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RQKernel(\n",
    "                alpha_prior=gpytorch.priors.SmoothedBoxPrior(0.8, 1.0),\n",
    "                lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(0.01, 5.0)\n",
    "            )\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, None, likelihood)  # Set train_y to None initially\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  \n",
    "], lr=0.001)\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "training_iter = 10000\n",
    "loss_threshold = 0.73\n",
    "stop_training = False\n",
    "\n",
    "for i in range(training_iter):\n",
    "    optimizer.zero_grad()\n",
    "    random_row_idx = torch.randint(0, subjins25.shape[0], (1,))\n",
    "    train_y = (torch.log(subjins25[random_row_idx]) - train_mean) / train_std\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    if (i + 1) % 100 == 0:\n",
    "        max_loss_idx = random_row_idx\n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f  Max Loss Row: %d' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.base_kernel.lengthscale.item(),\n",
    "            model.likelihood.noise.item(),\n",
    "            max_loss_idx.item()\n",
    "        ))\n",
    "    if loss.item() < loss_threshold:\n",
    "        print('Loss is below the threshold. Stopping training.')\n",
    "        stop_training = True\n",
    "        break\n",
    "    optimizer.step()\n",
    "    if i + 1 >= training_iter:\n",
    "        print('Exceeded maximum iterations. Stopping training.')\n",
    "        stop_training = True\n",
    "        break\n",
    "\n",
    "if stop_training:\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    num_samples = 300\n",
    "    total_samples = 5000000\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        test_x = train_x\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    new_test_x = train_x\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        new_samples = observed_pred.sample(torch.Size([total_samples]))\n",
    "        pred_mean_rescaledback = torch.exp(observed_pred.mean * train_std + train_mean)\n",
    "        lower_rescaledback = torch.exp(observed_pred.confidence_region()[0] * train_std + train_mean)\n",
    "        upper_rescaledback = torch.exp(observed_pred.confidence_region()[1] * train_std + train_mean)\n",
    "\n",
    "    new_samples_rescaled = torch.exp(new_samples * train_std + train_mean)\n",
    "    new_samples_rescaled_double = new_samples_rescaled.double()\n",
    "    xdatanp = np.array(train_x.unsqueeze(0))\n",
    "\n",
    "    \n",
    "# Save necessary variables to a MATLAB-compatible mat file\n",
    "savemat('prepare_fig1_confidence_data.mat', {\n",
    "    'test_x': test_x.numpy(),\n",
    "    'lower_rescaledback': lower_rescaledback.numpy(),\n",
    "    'upper_rescaledback': upper_rescaledback.numpy(),\n",
    "    'subjins25': subjins25.numpy()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb73e799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20869021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0380fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
